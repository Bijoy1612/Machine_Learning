# -*- coding: utf-8 -*-
"""image recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MFwObhZ_s7pyS1DeeDEKTmTRHHBJJyDa

### Program to classify images
"""

#imports
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras import layers
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

#Loading data
from keras.datasets import cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

#Viewing data
print(type(x_test))
print(type(y_test))
print(type(x_train))
print(type(y_train))

#shape of the arrays
print(x_test.shape)
print(y_test.shape)
print(x_train.shape)
print(y_train.shape)

#Viewing first image as array
index = 10
x_train[index]

#viewing first image as picture
img = plt.imshow(x_train[index])

#image label
print('Image label:', y_train[index])

#get image classification
classification = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck']
print('Image class: ', classification[y_train[index][0]])

#converting labels to set of 10 m=numbers to input into to the neural network
y_train_one_hot = to_categorical(y_train)
y_test_one_hot = to_categorical(y_test)

#printing new labels
print('y_train:', y_train_one_hot)
print('y_test:', y_test_one_hot)

#New label of image above
print('The one hot label :', y_train_one_hot[index])

#Normalize the pixels to be values between 0 and 1
x_train = x_train / 255
x_test = x_test / 255

x_train[index]

#Model architecture
model =  Sequential()

#Adding first Convolution layer
model.add(Conv2D(32, (3,3), activation='relu', input_shape = (32,32,3)))

#Adding 1st pooling layer
model.add(MaxPooling2D(pool_size= (2,2)))

#Adding 2nd Convolution layer
model.add(Conv2D(64, (5,5), activation='relu'))

#Adding 2nd pooling layer
model.add(MaxPooling2D(pool_size= (2,2)))

#Adding first flattening layer
model.add(Flatten())

#ADding Layer of 1000 nuerons
model.add(Dense(1000, activation='relu'))

#Adding a dropout layer
model.add(Dropout(0.5))

#ADding Layer of 500 nuerons
model.add(Dense(500, activation='relu'))

#Adding a dropout layer
model.add(Dropout(0.5))

#ADding Layer of 250 nuerons
model.add(Dense(250, activation='relu'))

#ADding Layer of 10 nuerons
model.add(Dense(10, activation='softmax'))

#compiling model
model.compile(loss = 'categorical_crossentropy',
              optimizer = 'adam',
              metrics = ['accuracy'])

#Training the model
hist = model.fit(x_train, y_train_one_hot, batch_size= 256, epochs= 11, validation_split= 0.2)

#Evaluating the model using test dataset
model.evaluate(x_test, y_test_one_hot)[1]

#Visualizing Model accuracy
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Val'], loc = 'upper left')
plt.show()

#Visualizing model loss
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Model loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Val'], loc = 'upper right')
plt.show()

#Testing the model
from google.colab import files
uploaded = files.upload()

#Showing image
uploaded_img = plt.imread('CRUISE.jpg')
img = plt.imshow(uploaded_img)

#Resizing image
from skimage.transform import resize
resized_img = resize(uploaded_img, (32,32,3))
img = plt.imshow(resized_img)

#Getting the models prediction
pred = model.predict(np.array([resized_img]))

#Showing predictions
pred

#Sorting predictions descending
list_index = [0,1,2,3,4,5,6,7, 8, 9]
x = pred

for i in range(10):
  for j in range(10):
    if x[0][list_index[i]] > x[0][list_index[j]]:
      temp = list_index[i]
      list_index[i] = list_index[j]
      list_index[j] = temp
  
#showing sorted label in order
print(list_index)

#print the first 5 most likely classifications
for i in range(5):
  print(classification[list_index[i]], ':', pred[0][list_index[i]]*100, '%')